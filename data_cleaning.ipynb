{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from pylab import rcParams\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# keras imports - comment them out or do `pip install keras`\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# gensim for pretrained word2vec model\n",
    "import gensim\n",
    "\n",
    "# for synopsis clean up\n",
    "import string\n",
    "\n",
    "# list of stopwords used by MySQL in MyISAM\n",
    "stop_words = [\"a's\" , \"able\" , \"about\" , \"above\" , \"according\" , \"accordingly\" , \"across\" , \"actually\" , \"after\" , \"afterwards\" , \"again\" , \"against\" , \"ain't\" , \"all\" , \"allow\" , \"allows\" , \"almost\" , \"alone\" , \"along\" , \"already\" , \"also\" , \"although\" , \"always\" , \"am\" , \"among\" , \"amongst\" , \"an\" , \"and\" , \"another\" , \"any\" , \"anybody\" , \"anyhow\" , \"anyone\" , \"anything\" , \"anyway\" , \"anyways\" , \"anywhere\" , \"apart\" , \"appear\" , \"appreciate\" , \"appropriate\" , \"are\" , \"aren't\" , \"around\" , \"as\" , \"aside\" , \"ask\" , \"asking\" , \"associated\" , \"at\" , \"available\" , \"away\" , \"awfully\" , \"be\" , \"became\" , \"because\" , \"become\" , \"becomes\" , \"becoming\" , \"been\" , \"before\" , \"beforehand\" , \"behind\" , \"being\" , \"believe\" , \"below\" , \"beside\" , \"besides\" , \"best\" , \"better\" , \"between\" , \"beyond\" , \"both\" , \"brief\" , \"but\" , \"by\" , \"c'mon\" , \"c's\" , \"came\" , \"can\" , \"can't\" , \"cannot\" , \"cant\" , \"cause\" , \"causes\" , \"certain\" , \"certainly\" , \"changes\" , \"clearly\" , \"co\" , \"com\" , \"come\" , \"comes\" , \"concerning\" , \"consequently\" , \"consider\" , \"considering\" , \"contain\" , \"containing\" , \"contains\" , \"corresponding\" , \"could\" , \"couldn't\" , \"course\" , \"currently\" , \"definitely\" , \"described\" , \"despite\" , \"did\" , \"didn't\" , \"different\" , \"do\" , \"does\" , \"doesn't\" , \"doing\" , \"don't\" , \"done\" , \"down\" , \"downwards\" , \"during\" , \"each\" , \"edu\" , \"eg\" , \"eight\" , \"either\" , \"else\" , \"elsewhere\" , \"enough\" , \"entirely\" , \"especially\" , \"et\" , \"etc\" , \"even\" , \"ever\" , \"every\" , \"everybody\" , \"everyone\" , \"everything\" , \"everywhere\" , \"ex\" , \"exactly\" , \"example\" , \"except\" , \"far\" , \"few\" , \"fifth\" , \"first\" , \"five\" , \"followed\" , \"following\" , \"follows\" , \"for\" , \"former\" , \"formerly\" , \"forth\" , \"four\" , \"from\" , \"further\" , \"furthermore\" , \"get\" , \"gets\" , \"getting\" , \"given\" , \"gives\" , \"go\" , \"goes\" , \"going\" , \"gone\" , \"got\" , \"gotten\" , \"greetings\" , \"had\" , \"hadn't\" , \"happens\" , \"hardly\" , \"has\" , \"hasn't\" , \"have\" , \"haven't\" , \"having\" , \"he\" , \"he's\" , \"hello\" , \"help\" , \"hence\" , \"her\" , \"here\" , \"here's\" , \"hereafter\" , \"hereby\" , \"herein\" , \"hereupon\" , \"hers\" , \"herself\" , \"hi\" , \"him\" , \"himself\" , \"his\" , \"hither\" , \"hopefully\" , \"how\" , \"howbeit\" , \"however\" , \"i'd\" , \"i'll\" , \"i'm\" , \"i've\" , \"ie\" , \"if\" , \"ignored\" , \"immediate\" , \"in\" , \"inasmuch\" , \"inc\" , \"indeed\" , \"indicate\" , \"indicated\" , \"indicates\" , \"inner\" , \"insofar\" , \"instead\" , \"into\" , \"inward\" , \"is\" , \"isn't\" , \"it\" , \"it'd\" , \"it'll\" , \"it's\" , \"its\" , \"itself\" , \"just\" , \"keep\" , \"keeps\" , \"kept\" , \"know\" , \"known\" , \"knows\" , \"last\" , \"lately\" , \"later\" , \"latter\" , \"latterly\" , \"least\" , \"less\" , \"lest\" , \"let\" , \"let's\" , \"like\" , \"liked\" , \"likely\" , \"little\" , \"look\" , \"looking\" , \"looks\" , \"ltd\" , \"mainly\" , \"many\" , \"may\" , \"maybe\" , \"me\" , \"mean\" , \"meanwhile\" , \"merely\" , \"might\" , \"more\" , \"moreover\" , \"most\" , \"mostly\" , \"much\" , \"must\" , \"my\" , \"myself\" , \"name\" , \"namely\" , \"nd\" , \"near\" , \"nearly\" , \"necessary\" , \"need\" , \"needs\" , \"neither\" , \"never\" , \"nevertheless\" , \"new\" , \"next\" , \"nine\" , \"no\" , \"nobody\" , \"non\" , \"none\" , \"noone\" , \"nor\" , \"normally\" , \"not\" , \"nothing\" , \"novel\" , \"now\" , \"nowhere\" , \"obviously\" , \"of\" , \"off\" , \"often\" , \"oh\" , \"ok\" , \"okay\" , \"old\" , \"on\" , \"once\" , \"one\" , \"ones\" , \"only\" , \"onto\" , \"or\" , \"other\" , \"others\" , \"otherwise\" , \"ought\" , \"our\" , \"ours\" , \"ourselves\" , \"out\" , \"outside\" , \"over\" , \"overall\" , \"own\" , \"particular\" , \"particularly\" , \"per\" , \"perhaps\" , \"placed\" , \"please\" , \"plus\" , \"possible\" , \"presumably\" , \"probably\" , \"provides\" , \"que\" , \"quite\" , \"qv\" , \"rather\" , \"rd\" , \"re\" , \"really\" , \"reasonably\" , \"regarding\" , \"regardless\" , \"regards\" , \"relatively\" , \"respectively\" , \"right\" , \"said\" , \"same\" , \"saw\" , \"say\" , \"saying\" , \"says\" , \"second\" , \"secondly\" , \"see\" , \"seeing\" , \"seem\" , \"seemed\" , \"seeming\" , \"seems\" , \"seen\" , \"self\" , \"selves\" , \"sensible\" , \"sent\" , \"serious\" , \"seriously\" , \"seven\" , \"several\" , \"shall\" , \"she\" , \"should\" , \"shouldn't\" , \"since\" , \"six\" , \"so\" , \"some\" , \"somebody\" , \"somehow\" , \"someone\" , \"something\" , \"sometime\" , \"sometimes\" , \"somewhat\" , \"somewhere\" , \"soon\" , \"sorry\" , \"specified\" , \"specify\" , \"specifying\" , \"still\" , \"sub\" , \"such\" , \"sup\" , \"sure\" , \"t's\" , \"take\" , \"taken\" , \"tell\" , \"tends\" , \"th\" , \"than\" , \"thank\" , \"thanks\" , \"thanx\" , \"that\" , \"that's\" , \"thats\" , \"the\" , \"their\" , \"theirs\" , \"them\" , \"themselves\" , \"then\" , \"thence\" , \"there\" , \"there's\" , \"thereafter\" , \"thereby\" , \"therefore\" , \"therein\" , \"theres\" , \"thereupon\" , \"these\" , \"they\" , \"they'd\" , \"they'll\" , \"they're\" , \"they've\" , \"think\" , \"third\" , \"this\" , \"thorough\" , \"thoroughly\" , \"those\" , \"though\" , \"three\" , \"through\" , \"throughout\" , \"thru\" , \"thus\" , \"to\" , \"together\" , \"too\" , \"took\" , \"toward\" , \"towards\" , \"tried\" , \"tries\" , \"truly\" , \"try\" , \"trying\" , \"twice\" , \"two\" , \"un\" , \"under\" , \"unfortunately\" , \"unless\" , \"unlikely\" , \"until\" , \"unto\" , \"up\" , \"upon\" , \"us\" , \"use\" , \"used\" , \"useful\" , \"uses\" , \"using\" , \"usually\" , \"value\" , \"various\" , \"very\" , \"via\" , \"viz\" , \"vs\" , \"want\" , \"wants\" , \"was\" , \"wasn't\" , \"way\" , \"we\" , \"we'd\" , \"we'll\" , \"we're\" , \"we've\" , \"welcome\" , \"well\" , \"went\" , \"were\" , \"weren't\" , \"what\" , \"what's\" , \"whatever\" , \"when\" , \"whence\" , \"whenever\" , \"where\" , \"where's\" , \"whereafter\" , \"whereas\" , \"whereby\" , \"wherein\" , \"whereupon\" , \"wherever\" , \"whether\" , \"which\" , \"while\" , \"whither\" , \"who\" , \"who's\" , \"whoever\" , \"whole\" , \"whom\" , \"whose\" , \"why\" , \"will\" , \"willing\" , \"wish\" , \"with\" , \"within\" , \"without\" , \"won't\" , \"wonder\" , \"would\" , \"wouldn't\" , \"yes\" , \"yet\" , \"you\" , \"you'd\" , \"you'll\" , \"you're\" , \"you've\" , \"your\" , \"yours\" , \"yourself\" , \"yourselves\" , \"zero\"]\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 6\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77911, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/tidy_anime.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_cols = ['animeID', 'title_english', 'type', 'source', 'producers', 'genre', 'studio',\n",
    "               'episodes', 'premiered', 'rating', 'score', 'scored_by', 'rank', 'popularity',\n",
    "               'members', 'favorites', 'synopsis']\n",
    "truncated_df = df[desired_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeID</th>\n",
       "      <th>title_english</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>producers</th>\n",
       "      <th>genre</th>\n",
       "      <th>studio</th>\n",
       "      <th>episodes</th>\n",
       "      <th>premiered</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>rank</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Action</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animeID title_english type    source      producers      genre   studio  \\\n",
       "0        1  Cowboy Bebop   TV  Original  Bandai Visual     Action  Sunrise   \n",
       "1        1  Cowboy Bebop   TV  Original  Bandai Visual  Adventure  Sunrise   \n",
       "2        1  Cowboy Bebop   TV  Original  Bandai Visual     Comedy  Sunrise   \n",
       "3        1  Cowboy Bebop   TV  Original  Bandai Visual      Drama  Sunrise   \n",
       "4        1  Cowboy Bebop   TV  Original  Bandai Visual     Sci-Fi  Sunrise   \n",
       "\n",
       "   episodes    premiered                          rating  score  scored_by  \\\n",
       "0      26.0  Spring 1998  R - 17+ (violence & profanity)   8.81     405664   \n",
       "1      26.0  Spring 1998  R - 17+ (violence & profanity)   8.81     405664   \n",
       "2      26.0  Spring 1998  R - 17+ (violence & profanity)   8.81     405664   \n",
       "3      26.0  Spring 1998  R - 17+ (violence & profanity)   8.81     405664   \n",
       "4      26.0  Spring 1998  R - 17+ (violence & profanity)   8.81     405664   \n",
       "\n",
       "   rank  popularity  members  favorites  \\\n",
       "0    26          39   795733      43460   \n",
       "1    26          39   795733      43460   \n",
       "2    26          39   795733      43460   \n",
       "3    26          39   795733      43460   \n",
       "4    26          39   795733      43460   \n",
       "\n",
       "                                            synopsis  \n",
       "0  In the year 2071, humanity has colonized sever...  \n",
       "1  In the year 2071, humanity has colonized sever...  \n",
       "2  In the year 2071, humanity has colonized sever...  \n",
       "3  In the year 2071, humanity has colonized sever...  \n",
       "4  In the year 2071, humanity has colonized sever...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_cols = ['animeID', 'title_english', 'type', 'source', 'producers', 'genre', 'studio',\n",
    "               'episodes', 'premiered', 'rating', 'score', 'scored_by', 'rank', 'popularity',\n",
    "               'members', 'favorites', 'synopsis']\n",
    "truncated_df = df[desired_cols]\n",
    "truncated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#change NaN to 0 in Premiered column\n",
    "\n",
    "truncated_df.loc[:,'premiered'] = truncated_df.loc[:,'premiered'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 30430 bad anime after filtering for english titled anime only\n",
      "removed 8678 bad anime after dropping NaN rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# filter out bad titles. Only want titles that have an english name\n",
    "\n",
    "orig_len = len(truncated_df)\n",
    "filtered_df = truncated_df[truncated_df['title_english'].notnull()]\n",
    "new_len = len(filtered_df)\n",
    "print (\"removed {} bad anime after filtering for english titled anime only\".format(orig_len - new_len))\n",
    "\n",
    "# drop NaN rows\n",
    "filtered_df.dropna(inplace=True)\n",
    "print (\"removed {} bad anime after dropping NaN rows\".format(new_len - len(filtered_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2855 unique anime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "c:\\users\\sidac\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "# currently the anime is duplicated, one row per genre per studio. We need to flatten all to one row\n",
    "# also need to do this for type, source, producers, rating\n",
    "\n",
    "all_ids = set(filtered_df['animeID'].unique()) # 1.8K anime IDs\n",
    "print (\"{} unique anime\".format(len(all_ids)))\n",
    "\n",
    "id_genre_mapping = {}\n",
    "for each_id in all_ids:\n",
    "    genre_list = list(filtered_df[truncated_df['animeID'] == each_id]['genre'])\n",
    "    id_genre_mapping[each_id] = genre_list\n",
    "    \n",
    "id_studio_mapping = {}\n",
    "for each_id in all_ids:\n",
    "    id_studio_mapping[each_id] = list(filtered_df[truncated_df['animeID'] == each_id]['studio'])\n",
    "    \n",
    "id_source_mapping = {}\n",
    "for each_id in all_ids:\n",
    "    id_source_mapping[each_id] = list(filtered_df[truncated_df['animeID'] == each_id]['source'])\n",
    "    \n",
    "id_producers_mapping = {}\n",
    "for each_id in all_ids:\n",
    "    id_producers_mapping[each_id] = list(filtered_df[truncated_df['animeID'] == each_id]['producers'])\n",
    "    \n",
    "id_rating_mapping = {}\n",
    "for each_id in all_ids:\n",
    "    id_rating_mapping[each_id] = list(filtered_df[truncated_df['animeID'] == each_id]['rating'])\n",
    "    \n",
    "id_type_mapping = {}\n",
    "for each_id in all_ids:\n",
    "    id_type_mapping[each_id] = list(filtered_df[truncated_df['animeID'] == each_id]['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distinct df, remove duplicates\n",
    "reduced_df = filtered_df.groupby('animeID').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will add 40 columns to the data\n",
    "all_genres = sorted(list(set([item for sublist in id_genre_mapping.values() for item in sublist])))\n",
    "all_studios = sorted(list(set([item for sublist in id_studio_mapping.values() for item in sublist])))\n",
    "all_sources = sorted(list(set([item for sublist in id_source_mapping.values() for item in sublist])))\n",
    "all_producers = sorted(list(set([item for sublist in id_producers_mapping.values() for item in sublist])))\n",
    "all_ratings = sorted(list(set([item for sublist in id_rating_mapping.values() for item in sublist])))\n",
    "all_types = sorted(list(set([item for sublist in id_type_mapping.values() for item in sublist])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeID</th>\n",
       "      <th>title_english</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>producers</th>\n",
       "      <th>genre</th>\n",
       "      <th>studio</th>\n",
       "      <th>episodes</th>\n",
       "      <th>premiered</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>rank</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Action</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: The Movie</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Original</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Action</td>\n",
       "      <td>Bones</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.41</td>\n",
       "      <td>120243</td>\n",
       "      <td>164</td>\n",
       "      <td>449</td>\n",
       "      <td>197791</td>\n",
       "      <td>776</td>\n",
       "      <td>Another day, another bounty—such is the life o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>Victor Entertainment</td>\n",
       "      <td>Action</td>\n",
       "      <td>Madhouse</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>8.30</td>\n",
       "      <td>212537</td>\n",
       "      <td>255</td>\n",
       "      <td>146</td>\n",
       "      <td>408548</td>\n",
       "      <td>10432</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>Bandai Visual</td>\n",
       "      <td>Action</td>\n",
       "      <td>Sunrise</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Summer 2002</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>7.33</td>\n",
       "      <td>32837</td>\n",
       "      <td>2371</td>\n",
       "      <td>1171</td>\n",
       "      <td>79397</td>\n",
       "      <td>537</td>\n",
       "      <td>Witches are individuals with special powers li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>Beet the Vandel Buster</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Toei Animation</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Fall 2004</td>\n",
       "      <td>PG - Children</td>\n",
       "      <td>7.03</td>\n",
       "      <td>4894</td>\n",
       "      <td>3544</td>\n",
       "      <td>3704</td>\n",
       "      <td>11708</td>\n",
       "      <td>14</td>\n",
       "      <td>It is the dark century and the people are suff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    animeID            title_english   type    source             producers  \\\n",
       "0         1             Cowboy Bebop     TV  Original         Bandai Visual   \n",
       "6         5  Cowboy Bebop: The Movie  Movie  Original               Sunrise   \n",
       "16        6                   Trigun     TV     Manga  Victor Entertainment   \n",
       "22        7       Witch Hunter Robin     TV  Original         Bandai Visual   \n",
       "28        8   Beet the Vandel Buster     TV     Manga              TV Tokyo   \n",
       "\n",
       "        genre          studio  episodes    premiered  \\\n",
       "0      Action         Sunrise      26.0  Spring 1998   \n",
       "6      Action           Bones       1.0            0   \n",
       "16     Action        Madhouse      26.0  Spring 1998   \n",
       "22     Action         Sunrise      26.0  Summer 2002   \n",
       "28  Adventure  Toei Animation      52.0    Fall 2004   \n",
       "\n",
       "                            rating  score  scored_by  rank  popularity  \\\n",
       "0   R - 17+ (violence & profanity)   8.81     405664    26          39   \n",
       "6   R - 17+ (violence & profanity)   8.41     120243   164         449   \n",
       "16       PG-13 - Teens 13 or older   8.30     212537   255         146   \n",
       "22       PG-13 - Teens 13 or older   7.33      32837  2371        1171   \n",
       "28                   PG - Children   7.03       4894  3544        3704   \n",
       "\n",
       "    members  favorites                                           synopsis  \n",
       "0    795733      43460  In the year 2071, humanity has colonized sever...  \n",
       "6    197791        776  Another day, another bounty—such is the life o...  \n",
       "16   408548      10432  Vash the Stampede is the man with a $$60,000,0...  \n",
       "22    79397        537  Witches are individuals with special powers li...  \n",
       "28    11708         14  It is the dark century and the people are suff...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_IDs = reduced_df.animeID.tolist()\n",
    "genres_new = []\n",
    "studios_new = []\n",
    "sources_new = []\n",
    "producers_new = []\n",
    "ratings_new = []\n",
    "types_new = []\n",
    "for each_id in anime_IDs:\n",
    "    genres_new.append(id_genre_mapping[each_id])\n",
    "    studios_new.append(id_studio_mapping[each_id])\n",
    "    sources_new.append(id_source_mapping[each_id])\n",
    "    producers_new.append(id_producers_mapping[each_id])\n",
    "    ratings_new.append(id_rating_mapping[each_id])\n",
    "    types_new.append(id_type_mapping[each_id])\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "encoded_genres = mlb.fit_transform(genres_new)\n",
    "encoded_studios = mlb.fit_transform(studios_new)\n",
    "encoded_sources = mlb.fit_transform(sources_new)\n",
    "encoded_producers = mlb.fit_transform(producers_new)\n",
    "encoded_ratings = mlb.fit_transform(ratings_new)\n",
    "encoded_types = mlb.fit_transform(types_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_columns_added = encoded_genres.shape[1]\n",
    "\n",
    "# for col_idx in range(genre_columns_added):\n",
    "#     reduced_df.insert(len(reduced_df.columns), \"genre_{}\".format(col_idx+1), encoded_genres[:, col_idx])\n",
    "    \n",
    "for col_idx in range(genre_columns_added):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"genre_{}\".format(all_genres[col_idx]), encoded_genres[:, col_idx])\n",
    "\n",
    "for col_idx in range(encoded_studios.shape[1]):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"studio_{}\".format(all_studios[col_idx]), encoded_studios[:, col_idx])\n",
    "    \n",
    "for col_idx in range(encoded_sources.shape[1]):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"source_{}\".format(all_sources[col_idx]), encoded_sources[:, col_idx])\n",
    "    \n",
    "for col_idx in range(encoded_producers.shape[1]):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"producer_{}\".format(all_producers[col_idx]), encoded_producers[:, col_idx])\n",
    "    \n",
    "for col_idx in range(encoded_ratings.shape[1]):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"rating_{}\".format(all_ratings[col_idx]), encoded_ratings[:, col_idx])\n",
    "    \n",
    "for col_idx in range(encoded_types.shape[1]):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"type_{}\".format(all_types[col_idx]), encoded_types[:, col_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animeID</th>\n",
       "      <th>title_english</th>\n",
       "      <th>episodes</th>\n",
       "      <th>premiered</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>rank</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>...</th>\n",
       "      <th>rating_PG - Children</th>\n",
       "      <th>rating_PG-13 - Teens 13 or older</th>\n",
       "      <th>rating_R - 17+ (violence &amp; profanity)</th>\n",
       "      <th>rating_R+ - Mild Nudity</th>\n",
       "      <th>type_Movie</th>\n",
       "      <th>type_Music</th>\n",
       "      <th>type_ONA</th>\n",
       "      <th>type_OVA</th>\n",
       "      <th>type_Special</th>\n",
       "      <th>type_TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>8.81</td>\n",
       "      <td>405664</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>795733</td>\n",
       "      <td>43460</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Cowboy Bebop: The Movie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.41</td>\n",
       "      <td>120243</td>\n",
       "      <td>164</td>\n",
       "      <td>449</td>\n",
       "      <td>197791</td>\n",
       "      <td>776</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Spring 1998</td>\n",
       "      <td>8.30</td>\n",
       "      <td>212537</td>\n",
       "      <td>255</td>\n",
       "      <td>146</td>\n",
       "      <td>408548</td>\n",
       "      <td>10432</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>Witch Hunter Robin</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Summer 2002</td>\n",
       "      <td>7.33</td>\n",
       "      <td>32837</td>\n",
       "      <td>2371</td>\n",
       "      <td>1171</td>\n",
       "      <td>79397</td>\n",
       "      <td>537</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>Beet the Vandel Buster</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Fall 2004</td>\n",
       "      <td>7.03</td>\n",
       "      <td>4894</td>\n",
       "      <td>3544</td>\n",
       "      <td>3704</td>\n",
       "      <td>11708</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    animeID            title_english  episodes    premiered  score  scored_by  \\\n",
       "0         1             Cowboy Bebop      26.0  Spring 1998   8.81     405664   \n",
       "6         5  Cowboy Bebop: The Movie       1.0            0   8.41     120243   \n",
       "16        6                   Trigun      26.0  Spring 1998   8.30     212537   \n",
       "22        7       Witch Hunter Robin      26.0  Summer 2002   7.33      32837   \n",
       "28        8   Beet the Vandel Buster      52.0    Fall 2004   7.03       4894   \n",
       "\n",
       "    rank  popularity  members  favorites  ... rating_PG - Children  \\\n",
       "0     26          39   795733      43460  ...                    0   \n",
       "6    164         449   197791        776  ...                    0   \n",
       "16   255         146   408548      10432  ...                    0   \n",
       "22  2371        1171    79397        537  ...                    0   \n",
       "28  3544        3704    11708         14  ...                    1   \n",
       "\n",
       "    rating_PG-13 - Teens 13 or older  rating_R - 17+ (violence & profanity)  \\\n",
       "0                                  0                                      1   \n",
       "6                                  0                                      1   \n",
       "16                                 1                                      0   \n",
       "22                                 1                                      0   \n",
       "28                                 0                                      0   \n",
       "\n",
       "    rating_R+ - Mild Nudity  type_Movie  type_Music  type_ONA  type_OVA  \\\n",
       "0                         0           0           0         0         0   \n",
       "6                         0           1           0         0         0   \n",
       "16                        0           0           0         0         0   \n",
       "22                        0           0           0         0         0   \n",
       "28                        0           0           0         0         0   \n",
       "\n",
       "    type_Special  type_TV  \n",
       "0              0        1  \n",
       "6              0        0  \n",
       "16             0        1  \n",
       "22             0        1  \n",
       "28             0        1  \n",
       "\n",
       "[5 rows x 1102 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df = reduced_df.drop(['type', 'source', 'producers', 'genre', 'studio', 'rating'], axis = 1)\n",
    "reduced_df.to_csv(r'data/one_hot_encode_complete.csv')\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Action           1122\n",
       "Comedy           520 \n",
       "Adventure        287 \n",
       "Slice of Life    179 \n",
       "Drama            136 \n",
       "Sci-Fi           111 \n",
       "Mystery          69  \n",
       "Music            59  \n",
       "Fantasy          54  \n",
       "Game             43  \n",
       "Harem            42  \n",
       "Military         25  \n",
       "Ecchi            22  \n",
       "Kids             21  \n",
       "Romance          21  \n",
       "Sports           21  \n",
       "Magic            16  \n",
       "Dementia         16  \n",
       "Historical       16  \n",
       "Psychological    13  \n",
       "Horror           12  \n",
       "Supernatural     9   \n",
       "Mecha            8   \n",
       "Demons           8   \n",
       "Space            6   \n",
       "School           5   \n",
       "Cars             3   \n",
       "Parody           2   \n",
       "Martial Arts     2   \n",
       "Seinen           2   \n",
       "Police           1   \n",
       "Samurai          1   \n",
       "Shounen          1   \n",
       "Josei            1   \n",
       "Thriller         1   \n",
       "Name: animeID, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Decreasing Count of Entries for each column value\n",
    "\n",
    "#set options to see full dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "reduced_df.groupby('genre').count().sort_values(by=[\"animeID\"], ascending=False)['animeID']\n",
    "    #Keep top 15? Add Horror, Historical?\n",
    "\n",
    "#reduced_df.groupby('studio').count().sort_values(by=[\"animeID\"], ascending=False)['animeID']\n",
    "    #Keep studios with 20+ records?\n",
    "\n",
    "#reduced_df.groupby('source').count().sort_values(by=[\"animeID\"], ascending=False)['animeID']\n",
    "    #Keep all 15?\n",
    "\n",
    "#reduced_df.groupby('producers').count().sort_values(by=[\"animeID\"], ascending=False)['animeID']\n",
    "    #Keep Producers with 30+ records?\n",
    "\n",
    "#reduced_df.groupby('rating').count().sort_values(by=[\"animeID\"], ascending=False)['animeID']\n",
    "    #Keep all except 'None'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Encoding textual data - tokenization approach\n",
    "* May want to look into cleaning all the synopsis first, ex: remove (), lower case, etc (disregarding this for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis_list = reduced_df['synopsis'].tolist()\n",
    "# synopsis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size =  21259\n",
      "max_seq_len =  290\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = None\n",
    "MAX_SEQ_LEN = 0\n",
    "\n",
    "# find vocab_size\n",
    "all_words = {}\n",
    "\n",
    "# DEBUG\n",
    "debug = False\n",
    "init = 0\n",
    "count = 100\n",
    "\n",
    "for synopsis in synopsis_list:\n",
    "\n",
    "    # =========================\n",
    "    if debug:\n",
    "        if init == count - 1:\n",
    "            print(\"Original Synopsis:\")\n",
    "            print(synopsis + \"\\n\")\n",
    "    # =========================\n",
    "    \n",
    "    # deletes synopsis credits e.g. [Written by MAL Rewrite], (Source: ANN)\n",
    "    if synopsis[-1] == \")\":\n",
    "        idx = synopsis.rfind(\"(\")\n",
    "        synopsis = synopsis[:idx]\n",
    "    elif synopsis[-1] == \"]\":\n",
    "        idx = synopsis.rfind(\"[\")\n",
    "        synopsis = synopsis[:idx]\n",
    "    \n",
    "    # deletes punctuation\n",
    "    punctuation = string.punctuation\n",
    "    for c in punctuation:\n",
    "        synopsis = synopsis.replace(c, \"\")\n",
    "    \n",
    "    synopsis = synopsis.lower()\n",
    "    \n",
    "    # =========================\n",
    "    if debug:\n",
    "        if init == count - 1:\n",
    "            print(\"Lower Case Synopsis Without Punctuation:\")\n",
    "            print(synopsis + \"\\n\")\n",
    "    # =========================\n",
    "\n",
    "    word_list = synopsis.split(\" \")\n",
    "    \n",
    "    \n",
    "    # =========================\n",
    "    if debug:\n",
    "        if init == count - 1:\n",
    "            print(\"Original Word List:\")\n",
    "            print(str(word_list) + \"\\n\")\n",
    "    # =========================\n",
    "    \n",
    "    # remove stop words\n",
    "    word_list = [x for x in word_list if x not in stop_words]\n",
    "    \n",
    "    \n",
    "    # =========================\n",
    "    if debug:\n",
    "        if init == count - 1:\n",
    "            print(\"Word List Without Stop Words:\")\n",
    "            print(str(word_list) + \"\\n\")\n",
    "        init += 1\n",
    "    # =========================\n",
    "    \n",
    "    # find max seq len\n",
    "    if len(word_list) > MAX_SEQ_LEN:\n",
    "        MAX_SEQ_LEN = len(word_list)\n",
    "        sent = word_list\n",
    "\n",
    "    for ea_word in word_list:\n",
    "        \n",
    "        if ea_word in all_words:\n",
    "            all_words[ea_word] += 1\n",
    "        else:\n",
    "            all_words[ea_word] = 1\n",
    "VOCAB_SIZE = len(all_words.keys())\n",
    "print ('vocab_size = ', VOCAB_SIZE)\n",
    "print ('max_seq_len = ', MAX_SEQ_LEN)\n",
    "# print (MAX_SEQ_LEN, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1867, 290)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_synopsis = [one_hot(x, VOCAB_SIZE) for x in synopsis_list]\n",
    "padded_synopsis = pad_sequences(encoded_synopsis, maxlen=MAX_SEQ_LEN, padding='pre')\n",
    "padded_synopsis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a746a3ed988e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load pretrained google word2vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/GoogleNews-vectors-negative300.bin.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mignore_ext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[0;34m(uri, mode, transport_params)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mfobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCHEMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/GoogleNews-vectors-negative300.bin.gz'"
     ]
    }
   ],
   "source": [
    "# load pretrained google word2vec model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get averaged word embedding\n",
    "EMBED_DIM = 300\n",
    "\n",
    "all_synopsis_vectors = np.empty((0, EMBED_DIM))\n",
    "print (all_synopsis_vectors.shape)\n",
    "for each_synopsis in synopsis_list:\n",
    "    synopsis_words = each_synopsis.split(\" \")\n",
    "    word_count = len(synopsis_words)\n",
    "    synopsis_sum_vector = np.zeros((EMBED_DIM,))\n",
    "    for each_word in synopsis_words:\n",
    "        try:\n",
    "            synopsis_sum_vector += model[each_word]\n",
    "        except:\n",
    "            # word not in pretrained vocab\n",
    "            pass\n",
    "    synopsis_avg_vector = (synopsis_sum_vector / word_count).reshape(1, -1)\n",
    "    all_synopsis_vectors = np.append(all_synopsis_vectors, synopsis_avg_vector, axis=0)\n",
    "all_synopsis_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis_columns_added = all_synopsis_vectors.shape[1]\n",
    "for col_idx in range(synopsis_columns_added):\n",
    "    reduced_df.insert(len(reduced_df.columns), \"synopsis_embedded_{}\".format(col_idx+1), all_synopsis_vectors[:, col_idx])\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
